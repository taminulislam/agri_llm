{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ðŸ“š Agricultural PDF to Text Extraction with Chandra OCR\n",
                "\n",
                "This notebook extracts text from agricultural textbook PDFs using **Chandra**, a state-of-the-art OCR model.\n",
                "\n",
                "## Features:\n",
                "- Complex tables and forms\n",
                "- Handwriting recognition\n",
                "- Mathematical formulas (LaTeX)\n",
                "- Multi-column layouts\n",
                "- 40+ languages\n",
                "\n",
                "## Output Formats:\n",
                "| Format | Best For | Description |\n",
                "|--------|----------|-------------|\n",
                "| **JSONL** | LLM Fine-tuning âœ… | One JSON object per line, easy to process |\n",
                "| Markdown | Human review | Readable format with formatting |\n",
                "| JSON | API/structured data | Single file, harder to stream |\n",
                "| CSV | Tabular analysis | Limited for long text |\n",
                "| TXT | Simple pretraining | No structure/metadata |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”§ Step 1: Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install Chandra OCR and dependencies\n",
                "!pip install chandra-ocr pymupdf pillow tqdm -q"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“ Step 2: Configure Paths"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "import os\n",
                "\n",
                "# ======= CONFIGURE THESE PATHS =======\n",
                "PDF_DIR = Path(\"../data/book\")  # Directory containing your PDFs\n",
                "OUTPUT_DIR = Path(\"../data/extracted\")  # Output directory\n",
                "# =====================================\n",
                "\n",
                "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "# List all PDFs\n",
                "pdf_files = list(PDF_DIR.glob(\"*.pdf\"))\n",
                "print(f\"Found {len(pdf_files)} PDF files:\")\n",
                "for pdf in pdf_files:\n",
                "    size_mb = pdf.stat().st_size / (1024 * 1024)\n",
                "    print(f\"  - {pdf.name} ({size_mb:.1f} MB)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ” Step 3: Analyze PDF Types"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import fitz  # PyMuPDF\n",
                "\n",
                "def analyze_pdf(pdf_path, sample_pages=5):\n",
                "    \"\"\"Check if PDF is digital (has text) or scanned (needs OCR).\"\"\"\n",
                "    doc = fitz.open(pdf_path)\n",
                "    total_chars = 0\n",
                "    pages_to_check = min(sample_pages, len(doc))\n",
                "    \n",
                "    for i in range(pages_to_check):\n",
                "        text = doc[i].get_text().strip()\n",
                "        total_chars += len(text)\n",
                "    \n",
                "    avg_chars = total_chars / pages_to_check if pages_to_check > 0 else 0\n",
                "    is_scanned = avg_chars < 100\n",
                "    \n",
                "    result = {\n",
                "        \"path\": pdf_path,\n",
                "        \"total_pages\": len(doc),\n",
                "        \"avg_chars_per_page\": avg_chars,\n",
                "        \"needs_ocr\": is_scanned,\n",
                "    }\n",
                "    doc.close()\n",
                "    return result\n",
                "\n",
                "# Analyze all PDFs\n",
                "print(\"PDF Analysis:\")\n",
                "print(\"-\" * 60)\n",
                "pdf_analysis = []\n",
                "for pdf in pdf_files:\n",
                "    info = analyze_pdf(pdf)\n",
                "    pdf_analysis.append(info)\n",
                "    status = \"ðŸ”´ SCANNED (needs OCR)\" if info[\"needs_ocr\"] else \"ðŸŸ¢ DIGITAL (fast)\"\n",
                "    print(f\"{pdf.name}: {info['total_pages']} pages | {status}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## âš¡ Step 4A: Fast Extraction (Digital PDFs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tqdm.notebook import tqdm\n",
                "import json\n",
                "\n",
                "def extract_digital_pdf(pdf_path, output_dir):\n",
                "    \"\"\"Extract text from digital PDFs without OCR.\"\"\"\n",
                "    doc = fitz.open(pdf_path)\n",
                "    pdf_name = Path(pdf_path).stem\n",
                "    records = []\n",
                "    \n",
                "    for i, page in enumerate(tqdm(doc, desc=f\"Extracting {pdf_name}\")):\n",
                "        text = page.get_text(\"text\").strip()\n",
                "        if text:\n",
                "            records.append({\n",
                "                \"text\": text,\n",
                "                \"source\": pdf_name,\n",
                "                \"page\": i + 1,\n",
                "                \"total_pages\": len(doc)\n",
                "            })\n",
                "    \n",
                "    doc.close()\n",
                "    \n",
                "    # Save as JSONL (best for fine-tuning)\n",
                "    jsonl_path = output_dir / f\"{pdf_name}.jsonl\"\n",
                "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
                "        for record in records:\n",
                "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
                "    \n",
                "    # Save as Markdown (for preview)\n",
                "    md_path = output_dir / f\"{pdf_name}.md\"\n",
                "    with open(md_path, 'w', encoding='utf-8') as f:\n",
                "        for record in records:\n",
                "            f.write(f\"<!-- Page {record['page']} -->\\n\\n{record['text']}\\n\\n---\\n\\n\")\n",
                "    \n",
                "    print(f\"Saved {len(records)} pages: {jsonl_path}\")\n",
                "    return records\n",
                "\n",
                "# Extract digital PDFs\n",
                "digital_pdfs = [info for info in pdf_analysis if not info[\"needs_ocr\"]]\n",
                "for info in digital_pdfs:\n",
                "    extract_digital_pdf(info['path'], OUTPUT_DIR)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ¤– Step 4B: Chandra OCR (Scanned PDFs)\n",
                "\n",
                "Use Chandra for high-quality OCR on scanned documents."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Using Chandra CLI (recommended for batch processing)\n",
                "scanned_pdfs = [info for info in pdf_analysis if info[\"needs_ocr\"]]\n",
                "\n",
                "if scanned_pdfs:\n",
                "    print(\"Processing scanned PDFs with Chandra OCR...\")\n",
                "    print(\"This may take several minutes per document.\\n\")\n",
                "    \n",
                "    for info in scanned_pdfs:\n",
                "        pdf_path = str(info['path'])\n",
                "        output_path = str(OUTPUT_DIR)\n",
                "        \n",
                "        print(f\"Processing: {info['path'].name}\")\n",
                "        # Use HuggingFace method (local, no server needed)\n",
                "        !chandra \"{pdf_path}\" \"{output_path}\" --method hf --no-images\n",
                "else:\n",
                "    print(\"No scanned PDFs found. All PDFs extracted in Step 4A.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“Š Step 5: Convert Markdown to JSONL"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import re\n",
                "\n",
                "def markdown_to_jsonl(md_path):\n",
                "    \"\"\"Convert markdown output to JSONL format.\"\"\"\n",
                "    md_path = Path(md_path)\n",
                "    \n",
                "    with open(md_path, 'r', encoding='utf-8') as f:\n",
                "        content = f.read()\n",
                "    \n",
                "    # Split by page markers\n",
                "    if '<!-- Page' in content:\n",
                "        pages = re.split(r'<!-- Page \\d+ -->', content)\n",
                "        pages = [p.strip().rstrip('---').strip() for p in pages if p.strip()]\n",
                "    else:\n",
                "        pages = [content.strip()]\n",
                "    \n",
                "    source = md_path.stem\n",
                "    records = []\n",
                "    \n",
                "    for i, text in enumerate(pages):\n",
                "        if text:\n",
                "            records.append({\n",
                "                \"text\": text,\n",
                "                \"source\": source,\n",
                "                \"page\": i + 1,\n",
                "                \"total_pages\": len(pages)\n",
                "            })\n",
                "    \n",
                "    jsonl_path = md_path.with_suffix('.jsonl')\n",
                "    with open(jsonl_path, 'w', encoding='utf-8') as f:\n",
                "        for record in records:\n",
                "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
                "    \n",
                "    print(f\"Converted {len(records)} pages: {jsonl_path}\")\n",
                "    return records\n",
                "\n",
                "# Convert all markdown files\n",
                "md_files = list(OUTPUT_DIR.glob(\"**/*.md\"))\n",
                "for md_file in md_files:\n",
                "    markdown_to_jsonl(md_file)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ”— Step 6: Merge All Files into Single Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def merge_jsonl_files(input_dir, output_file):\n",
                "    \"\"\"Merge all JSONL files into a single dataset.\"\"\"\n",
                "    input_dir = Path(input_dir)\n",
                "    jsonl_files = list(input_dir.glob(\"**/*.jsonl\"))\n",
                "    \n",
                "    all_records = []\n",
                "    for jsonl_path in jsonl_files:\n",
                "        if jsonl_path.name == Path(output_file).name:\n",
                "            continue  # Skip output file if it exists\n",
                "        with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
                "            for line in f:\n",
                "                if line.strip():\n",
                "                    all_records.append(json.loads(line))\n",
                "    \n",
                "    with open(output_file, 'w', encoding='utf-8') as f:\n",
                "        for record in all_records:\n",
                "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
                "    \n",
                "    print(f\"\\nMerged Dataset:\")\n",
                "    print(f\"  Total records: {len(all_records)}\")\n",
                "    print(f\"  Sources: {len(set(r['source'] for r in all_records))}\")\n",
                "    print(f\"  Output: {output_file}\")\n",
                "    \n",
                "    return all_records\n",
                "\n",
                "DATASET_FILE = OUTPUT_DIR / \"agricultural_textbooks.jsonl\"\n",
                "all_data = merge_jsonl_files(OUTPUT_DIR, DATASET_FILE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ“‹ Step 7: Preview Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preview first 3 records\n",
                "with open(DATASET_FILE, 'r', encoding='utf-8') as f:\n",
                "    samples = [json.loads(line) for i, line in enumerate(f) if i < 3]\n",
                "\n",
                "for i, sample in enumerate(samples):\n",
                "    print(f\"{'='*60}\")\n",
                "    print(f\"Record {i+1}: {sample['source']} - Page {sample['page']}\")\n",
                "    print(f\"{'='*60}\")\n",
                "    preview = sample['text'][:800]\n",
                "    print(preview + (\"...\" if len(sample['text']) > 800 else \"\"))\n",
                "    print()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "# ðŸ“– Dataset Format Recommendations for LLM Fine-Tuning\n",
                "\n",
                "## Why JSONL is Best:\n",
                "\n",
                "1. **Streaming**: Process line-by-line without loading entire file\n",
                "2. **Metadata**: Store source, page numbers, etc. with each record\n",
                "3. **Flexibility**: Easy to filter, sample, or split\n",
                "4. **Standard**: Used by OpenAI, HuggingFace, and most fine-tuning frameworks\n",
                "\n",
                "## Next Steps for Fine-Tuning:\n",
                "\n",
                "1. **Continued Pre-training**: Use raw JSONL as-is\n",
                "2. **Instruction Tuning**: Convert to Q&A pairs (see Step 8 below)\n",
                "3. **RAG**: Create embeddings and store in vector database"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ðŸ’¡ Step 8: Create Q&A Training Format (Optional)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_qa_format(jsonl_path, output_path, format_type=\"chatml\"):\n",
                "    \"\"\"Convert raw text to Q&A training format.\n",
                "    \n",
                "    format_type:\n",
                "        - 'chatml': ChatML format for OpenAI/Llama fine-tuning\n",
                "        - 'alpaca': Alpaca instruction format\n",
                "    \"\"\"\n",
                "    with open(jsonl_path, 'r', encoding='utf-8') as f:\n",
                "        records = [json.loads(line) for line in f if line.strip()]\n",
                "    \n",
                "    output_records = []\n",
                "    \n",
                "    for r in records:\n",
                "        if format_type == \"chatml\":\n",
                "            # ChatML format (OpenAI, Llama-3, etc.)\n",
                "            output_records.append({\n",
                "                \"messages\": [\n",
                "                    {\"role\": \"system\", \"content\": \"You are an agricultural expert. Answer questions based on the provided context.\"},\n",
                "                    {\"role\": \"user\", \"content\": f\"Context from {r['source']} (page {r['page']}):\\n\\n{r['text'][:3000]}\\n\\n[Add your question here]\"},\n",
                "                    {\"role\": \"assistant\", \"content\": \"[Add your answer here - requires annotation]\"}\n",
                "                ]\n",
                "            })\n",
                "        elif format_type == \"alpaca\":\n",
                "            # Alpaca instruction format\n",
                "            output_records.append({\n",
                "                \"instruction\": \"Answer the following agricultural question based on the context.\",\n",
                "                \"input\": f\"Context: {r['text'][:3000]}\\n\\nQuestion: [Add question]\",\n",
                "                \"output\": \"[Add answer - requires annotation]\"\n",
                "            })\n",
                "    \n",
                "    with open(output_path, 'w', encoding='utf-8') as f:\n",
                "        for record in output_records:\n",
                "            f.write(json.dumps(record, ensure_ascii=False) + '\\n')\n",
                "    \n",
                "    print(f\"Created {len(output_records)} training examples: {output_path}\")\n",
                "    print(\"\\nNOTE: You need to add actual Q&A pairs. Consider:\")\n",
                "    print(\"  1. Manual annotation\")\n",
                "    print(\"  2. Use GPT-4 to generate Q&A pairs\")\n",
                "    print(\"  3. Extract questions from textbook exercises\")\n",
                "\n",
                "# Optional: Create training format templates\n",
                "# create_qa_format(DATASET_FILE, OUTPUT_DIR / \"training_chatml.jsonl\", \"chatml\")\n",
                "# create_qa_format(DATASET_FILE, OUTPUT_DIR / \"training_alpaca.jsonl\", \"alpaca\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## âœ… Summary\n",
                "\n",
                "Your extracted dataset is saved at: `data/extracted/agricultural_textbooks.jsonl`\n",
                "\n",
                "### JSONL Record Format:\n",
                "```json\n",
                "{\"text\": \"...\", \"source\": \"weed-control\", \"page\": 1, \"total_pages\": 100}\n",
                "```\n",
                "\n",
                "### Usage with Popular Frameworks:\n",
                "```python\n",
                "# HuggingFace datasets\n",
                "from datasets import load_dataset\n",
                "dataset = load_dataset('json', data_files='agricultural_textbooks.jsonl')\n",
                "\n",
                "# Direct loading\n",
                "import json\n",
                "with open('agricultural_textbooks.jsonl') as f:\n",
                "    data = [json.loads(line) for line in f]\n",
                "```"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}